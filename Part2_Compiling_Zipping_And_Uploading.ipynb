{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_logger():\n",
    "    create_directory(\"Files2\")\n",
    "    loglevel = logging.INFO            # DEBUG, CRITICAL, WARNING, ERROR\n",
    "    logger = logging.getLogger(\"Application_Logs\")\n",
    "    logger2 = logging.getLogger(\"Application_Logs_Stream\")\n",
    "    if not getattr(logger, 'handler_set', None):\n",
    "        logger.setLevel(logging.INFO)\n",
    "#         Logfile handler\n",
    "        handler = logging.FileHandler('Files2/logs.log')\n",
    "        handler2 = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        logger.addHandler(handler2)\n",
    "        logger.setLevel(loglevel)\n",
    "        logger.handler_set = True\n",
    "#       Stream Handler\n",
    "    if not getattr(logger, 'handler_set', None):\n",
    "        logger2.setLevel(logging.INFO)\n",
    "        handler2 = logging.StreamHandler()\n",
    "        handler2.setFormatter(formatter)\n",
    "        logger2.addHandler(handler2)\n",
    "        logger2.setLevel(loglevel)\n",
    "        logger2.handler_set = True\n",
    "        \n",
    "    return logger\n",
    "\n",
    "\n",
    "def create_directory(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, output_path):\n",
    "    \"\"\"Zip the contents of an entire folder (with that folder included\n",
    "    in the archive). Empty subfolders will be included in the archive\n",
    "    as well.\n",
    "    \"\"\"\n",
    "    parent_folder = os.path.dirname(folder_path)\n",
    "    # Retrieve the paths of the folder contents.\n",
    "    contents = os.walk(folder_path)\n",
    "\n",
    "    zip_file = zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED)\n",
    "    for root, folders, files in contents:\n",
    "        # Include all subfolders, including empty ones.\n",
    "        for folder_name in folders:\n",
    "            absolute_path = os.path.join(root, folder_name)\n",
    "            relative_path = absolute_path.replace(parent_folder + '\\\\', '')\n",
    "            zip_file.write(absolute_path, relative_path)\n",
    "        for file_name in files:\n",
    "            absolute_path = os.path.join(root, file_name)\n",
    "            relative_path = absolute_path.replace(parent_folder + '\\\\', '')\n",
    "            zip_file.write(absolute_path, relative_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling Data\n",
      "INFO:Application_Logs:Compiling Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress : 77%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Problem2_Compiled Files Zipped\n",
      "INFO:Application_Logs:Problem2_Compiled Files Zipped\n",
      "Uploading to Amazon s3\n",
      "INFO:Application_Logs:Uploading to Amazon s3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress : 92%.........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files Uploaded to S3\n",
      "INFO:Application_Logs:Files Uploaded to S3\n",
      "Compiled and uploaded to Amazon s3\n",
      "INFO:Application_Logs:Compiled and uploaded to Amazon s3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress : 100%"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging, sys, time\n",
    "import zipfile\n",
    "import boto\n",
    "import boto.s3\n",
    "from boto.s3.key import Key\n",
    "\n",
    "logger = get_logger()\n",
    "logger.info(\"Compiling Data\")\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 0)\n",
    "time.sleep(1)\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 1)\n",
    "time.sleep(1)\n",
    "new_dir = \"Problem2_Compiled\"\n",
    "create_directory(new_dir)\n",
    "\n",
    "dir_path = \"Files2\"\n",
    "ls_dir = os.listdir(dir_path)\n",
    "\n",
    "\n",
    "year=0 \n",
    "\n",
    "aws_access_read = \"\"\n",
    "aws_secret_read = \"\"\n",
    "\n",
    "with open(\"config.txt\") as configfile:\n",
    "    for line in configfile:\n",
    "        name, val = line.partition(\"=\")[::2]\n",
    "        if (name.strip()==\"aws_access_key\"):\n",
    "            aws_access_read = val\n",
    "        elif (name.strip()==\"aws_secret_key\"):\n",
    "            aws_secret_read = val\n",
    "            \n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 10)\n",
    "time.sleep(1)\n",
    "\n",
    "aws_access_key = aws_access_read.strip()\n",
    "aws_secret_key = aws_secret_read.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Finding Directory or year for which csv are present (this will look for the last folder only)\n",
    "for file in ls_dir:\n",
    "    regexp = re.compile(r'.txt|.log')\n",
    "#     print(file)\n",
    "    if not(regexp.search(file)):\n",
    "        year = file\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 4)    \n",
    "# Setting Directory for the year    \n",
    "if not(year == 0):\n",
    "#     print(year)\n",
    "    dir_path += \"/\" + str(year)\n",
    "else:\n",
    "    print(\"No Files found! Ending Program\")\n",
    "    sys.exit()\n",
    "\n",
    "#Going into the Cleaned Files Directory    \n",
    "\n",
    "# Compiling Cleaned Files\n",
    "dir_path += \"/Cleaned_Files\"\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 7)\n",
    "ls_dir = os.listdir(dir_path)\n",
    "\n",
    "x = 7\n",
    "for file in ls_dir:\n",
    "    x += 3\n",
    "    regexp = re.compile(r'Cleaned')\n",
    "    if(regexp.search(file)):\n",
    "        filePath = dir_path + \"/\" + file\n",
    "        fileData = pd.read_csv(filePath,header = 0)    \n",
    "        compiled_file_path = new_dir + \"/Cleaned.csv\"\n",
    "        if(os.path.exists(compiled_file_path)):\n",
    "            with open(compiled_file_path , 'a') as f:\n",
    "                fileData.to_csv(f, header=False)\n",
    "        else:\n",
    "            fileData.to_csv(compiled_file_path, header=True)\n",
    "    sys.stdout.write(\"\\rProgress : %d%%\" % x)\n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "# ____________for loop ends_____________________________\n",
    "# Compiling Cleaned Files Ends    \n",
    "    \n",
    "\n",
    "    \n",
    "    #Going into the Summary Files Directory\n",
    "# Compiling Summary Files\n",
    "dir_path += \"/Summary\"\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 24)\n",
    "ls_dir = os.listdir(dir_path)\n",
    "\n",
    "for file in ls_dir:\n",
    "    x += 1\n",
    "    regexp = re.compile(r'Count_Accession_For_Error_Code')\n",
    "    if(regexp.search(file)):\n",
    "        filePath = dir_path + \"/\" + file\n",
    "        fileData = pd.read_csv(filePath,header = 0)    \n",
    "        compiled_file_path = new_dir + \"/Count_Accession_For_Error_Code.csv\"\n",
    "        if(os.path.exists(compiled_file_path)):\n",
    "            with open(compiled_file_path , 'a') as f:\n",
    "                fileData.to_csv(f, header=False)\n",
    "        else:\n",
    "            fileData.to_csv(compiled_file_path, header=True)\n",
    "\n",
    "            \n",
    "    regexp = re.compile(r'Count_Unique_Accession_Number_Cleaned')\n",
    "    if(regexp.search(file)):\n",
    "        filePath = dir_path + \"/\" + file\n",
    "        fileData = pd.read_csv(filePath,header = 0)    \n",
    "        compiled_file_path = new_dir + \"/Count_Unique_Accession_Number_Cleaned.csv\"\n",
    "        if(os.path.exists(compiled_file_path)):\n",
    "            with open(compiled_file_path , 'a') as f:\n",
    "                fileData.to_csv(f, header=False)\n",
    "        else:\n",
    "            fileData.to_csv(compiled_file_path, header=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "    regexp = re.compile(r'Count_All_Accession_Number')\n",
    "    if(regexp.search(file)):\n",
    "        filePath = dir_path + \"/\" + file\n",
    "        fileData = pd.read_csv(filePath,header = 0)    \n",
    "        compiled_file_path = new_dir + \"/Count_All_Accession_Number.csv\"\n",
    "        if(os.path.exists(compiled_file_path)):\n",
    "            with open(compiled_file_path , 'a') as f:\n",
    "                fileData.to_csv(f, header=False)\n",
    "        else:\n",
    "            fileData.to_csv(compiled_file_path, header=True)\n",
    "            \n",
    "            \n",
    "    regexp = re.compile(r'Count_of_files_by_extention')\n",
    "    if(regexp.search(file)):\n",
    "        filePath = dir_path + \"/\" + file\n",
    "        fileData = pd.read_csv(filePath,header = 0)    \n",
    "        compiled_file_path = new_dir + \"/Count_of_files_by_extention.csv\"\n",
    "        if(os.path.exists(compiled_file_path)):\n",
    "            with open(compiled_file_path , 'a') as f:\n",
    "                fileData.to_csv(f, header=False)\n",
    "        else:\n",
    "            fileData.to_csv(compiled_file_path, header=True)\n",
    "    sys.stdout.write(\"\\rProgress : %d%%\" % x)\n",
    "\n",
    "# ____________for loop ends_____________________________\n",
    "# Compiling Summary Files Ends\n",
    "\n",
    "\n",
    "zip_folder('Problem2_Compiled', 'Problem2_Compiled.zip')\n",
    "logger.info(\"Problem2_Compiled Files Zipped\")\n",
    "\n",
    "\n",
    "logger.info(\"Uploading to Amazon s3\")\n",
    " #Uploading Files to S3\n",
    "        \n",
    "bucket_name = aws_access_key.lower() \n",
    "conn = boto.connect_s3(aws_access_key,aws_secret_key)\n",
    "\n",
    "#Checking if bucket exists\n",
    "bucket = conn.lookup(bucket_name)\n",
    "if bucket is None:\n",
    "    bucket = conn.create_bucket(bucket_name, location=boto.s3.connection.Location.DEFAULT)\n",
    "\n",
    "testfile = \"Problem2_Compiled.zip\"\n",
    "def percent_cb(complete, total):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "k = Key(bucket)\n",
    "k.key = testfile\n",
    "k.set_contents_from_filename(testfile,\n",
    "cb=percent_cb, num_cb=10)\n",
    "logger.info(\"Files Uploaded to S3\")\n",
    "\n",
    "logger.info(\"Compiled and uploaded to Amazon s3\")\n",
    "logger.removeHandler(\"handler\")\n",
    "logging.shutdown()\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 100)\n",
    "sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
