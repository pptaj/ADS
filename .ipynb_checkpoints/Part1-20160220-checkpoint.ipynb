{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-c991836b8d71>, line 78)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-c991836b8d71>\"\u001b[0;36m, line \u001b[0;32m78\u001b[0m\n\u001b[0;31m    if a is not None:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#10 K = 0001652044-17-000008, \n",
    "#1652044\n",
    "\n",
    "import time\n",
    "import urllib.response\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import string\n",
    "from string import punctuation\n",
    "def create_csv(cik,document_accession_number, url):\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html,\"html5lib\")\n",
    "    all_tables = soup.find_all(\"table\", border=1)\n",
    "    type(all_tables)\n",
    "    tables = []\n",
    "    for x in all_tables:\n",
    "        tables.append(x)\n",
    "    i=0\n",
    "    for table in tables:\n",
    "        data = []\n",
    "        i= i + 1\n",
    "        all_rows =  table.find_all('tr')\n",
    "        for row in all_rows:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [(''.join(ch.strip('[\\n,$]') for ch in ele.text)).strip() for ele in cols]\n",
    "            #print(cols)\n",
    "            data.append([ele for ele in cols if ele])\n",
    "        write_file = open(\"Files/\" + cik + \"_\" + document_accession_number + \"_\" + str(time.time()) + \"_table_\" + str(i) + '.csv', 'w')\n",
    "        for row in data:\n",
    "            for column in row:\n",
    "                write_file.write(column)\n",
    "                write_file.write(',')\n",
    "            write_file.write('\\n')\n",
    "        write_file.close()   \n",
    "    #intitalize row and column numbers\n",
    "    \n",
    "    \n",
    "# READ CIK, ACCESSION NUMBER AND AMAZON KEYS FROM config.txt\n",
    "cik_read =\"\"\n",
    "accn_num_read =\"\"\n",
    "aws_read = \"\"\n",
    "with open(\"config.txt\") as configfile:\n",
    "    for line in configfile:\n",
    "        name, val = line.partition(\"=\")[::2]\n",
    "        if (name==\"cik\"):\n",
    "            cik_read = val\n",
    "        elif (name==\"accession_number\"):\n",
    "            accn_num_read = val\n",
    "        elif (name==\"aws_key\"):\n",
    "            aws_read = val\n",
    "\n",
    "print(\"cik_read = \"+ cik_read.strip()+ \"accn_read = \" + accn_num_read.strip())\n",
    "\n",
    "# cik = input(\"Please enter CIK: \")\n",
    "# document_accession_number = input(\"Please enter accession number: \")\n",
    "\n",
    "cik = cik_read.strip()\n",
    "document_accession_number = accn_num_read.strip()\n",
    "aws_key = aws_read.strip()\n",
    "\n",
    "\n",
    "document_accession_number_without_dashes = re.sub('[-]', '', document_accession_number)\n",
    "url = \"https://www.sec.gov/Archives/edgar/data/\" + str(int(cik)) + \"/\" + document_accession_number_without_dashes + \"/\"\n",
    "url = url + document_accession_number +\"-index.html\"\n",
    "\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "cells = soup.findAll('td')\n",
    "s = \"https://www.sec.gov\"\n",
    "for cell in cells :\n",
    "    if cell.get_text().find('10-Q') > -1 :\n",
    "        a = cell.find_next_sibling(\"td\").find('a',href=True)\n",
    "    if a is not None:\n",
    "        if 'href' in a.attrs:\n",
    "            result = a['href']\n",
    "            s+=result\n",
    "            break\n",
    "    elif cell.get_text().find('10-K') > -1 :\n",
    "        a = cell.find_previous_sibling(\"td\").find('a')\n",
    "    if a is not None:\n",
    "        if 'href' in a.attrs:\n",
    "            result = a['href']\n",
    "            s+=result\n",
    "            print(s)\n",
    "            break\n",
    "\n",
    "    create_csv(cik,document_accession_number, s) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
