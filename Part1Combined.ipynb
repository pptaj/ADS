{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter CIK: 1652044\n",
      "Please enter accession number: 0001652044-17-000008\n",
      "https://www.sec.gov/Archives/edgar/data/1652044/000165204417000008/goog10-kq42016.htm\n"
     ]
    }
   ],
   "source": [
    "import urllib.response\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import string\n",
    "from string import punctuation\n",
    "def create_csv(url):\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    all_tables = soup.find_all(\"table\", border=1)\n",
    "    type(all_tables)\n",
    "    tables = []\n",
    "    for x in all_tables:\n",
    "        tables.append(x)\n",
    "    i=0\n",
    "    for table in tables:\n",
    "        data = []\n",
    "        i= i + 1\n",
    "        all_rows =  table.find_all('tr')\n",
    "        for row in all_rows:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [(''.join(ch.strip('[\\n,$]') for ch in ele.text)).strip() for ele in cols]\n",
    "            #print(cols)\n",
    "            data.append([ele for ele in cols if ele])\n",
    "        write_file = open('/home/sneha/Projects /ADS/RetrievedDocs/'+str(i)+ '.csv', 'w')\n",
    "        for row in data:\n",
    "            for column in row:\n",
    "                write_file.write(column)\n",
    "                write_file.write(',')\n",
    "            write_file.write('\\n')\n",
    "        write_file.close()   \n",
    "    \n",
    "    #intitalize row and column numbers\n",
    "cik = input(\"Please enter CIK: \")\n",
    "document_accession_number = input(\"Please enter accession number: \")\n",
    "document_accession_number_without_dashes = re.sub('[-]', '', document_accession_number)\n",
    "url = \"https://www.sec.gov/Archives/edgar/data/\" + str(int(cik)) + \"/\" + document_accession_number_without_dashes + \"/\"\n",
    "url = url + document_accession_number +\"-index.html\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "cells = soup.findAll('td')\n",
    "s = \"https://www.sec.gov\"\n",
    "for cell in cells :\n",
    "    if cell.get_text().find('10-Q') > -1 :\n",
    "        a = cell.find_next_sibling(\"td\").find('a',href=True)\n",
    "        if a is not None:\n",
    "         if 'href' in a.attrs:\n",
    "            result = a['href']\n",
    "            s+=result\n",
    "            break\n",
    "    elif cell.get_text().find('10-K') > -1 :\n",
    "        a = cell.find_previous_sibling(\"td\").find('a')\n",
    "        if a is not None:\n",
    "         if 'href' in a.attrs:\n",
    "            result = a['href']\n",
    "            s+=result\n",
    "            print(s)\n",
    "            break\n",
    "        \n",
    "create_csv(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_csv(url):\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    all_tables = soup.find_all(\"table\", border=1)\n",
    "    type(all_tables)\n",
    "    tables = []\n",
    "    for x in all_tables:\n",
    "        tables.append(x)\n",
    "    i=0\n",
    "    for table in tables:\n",
    "        data = []\n",
    "        i= i + 1\n",
    "        all_rows =  table.find_all('tr')\n",
    "        for row in all_rows:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [(''.join(ch.strip('[\\n,$]') for ch in ele.text)).strip() for ele in cols]\n",
    "            #print(cols)\n",
    "            data.append([ele for ele in cols if ele])\n",
    "        write_file = open('/C:/Users/taj/Desktop/ADScsv'+str(i)+ '.csv', 'w')\n",
    "        for row in data:\n",
    "            for column in row:\n",
    "                write_file.write(column)\n",
    "                write_file.write(',')\n",
    "            write_file.write('\\n')\n",
    "        write_file.close()   \n",
    "    #intitalize row and column numbers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
