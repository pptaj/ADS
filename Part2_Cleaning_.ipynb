{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_date(fileData):\n",
    "    splitter = fileData['date'].apply(lambda x: x.split('-'))\n",
    "    fileData['year'] = splitter.apply(lambda x: x[0])\n",
    "    fileData['month'] = splitter.apply(lambda x: x[1])\n",
    "    fileData['dayOfMonth'] = splitter.apply(lambda x: x[2])\n",
    "    return fileData\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_size(fileData):\n",
    "    if (any(fileData['code'] == 304)):\n",
    "        fileData['size'].fillna(0, inplace=True)\n",
    "    return fileData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_time(fileData):\n",
    "    splitter = fileData['time'].apply(lambda x: x.split(':'))\n",
    "    fileData['h'] = splitter.apply(lambda x: x[0])\n",
    "    fileData['m'] = splitter.apply(lambda x: x[1])\n",
    "    fileData['s'] = splitter.apply(lambda x: x[2])\n",
    "    return fileData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_directory(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_code(fileData):\n",
    "    fileData = fileData[(fileData['code'] != 0)]\n",
    "    return fileData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processed_csvs(fileData, filePath,i):\n",
    "    fp = re.split('/', filePath, flags=re.IGNORECASE)\n",
    "    new_file_path = fp[0] + \"/\" + fp[1]  + \"/\"\n",
    "    create_directory(new_file_path + \"Cleaned_Files\")\n",
    "    new_file_path += \"Cleaned_Files/Cleaned_\" + fp[2] \n",
    "    fileData.to_csv(new_file_path, sep=',')\n",
    "#     if(i==1):\n",
    "#         fileData.to_csv(new_file_path, sep=',')\n",
    "#     else:\n",
    "#         with open(new_file_path, 'a') as f:\n",
    "#             fileData.to_csv(f, header=False)\n",
    "#     i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def true_extention(fileData):\n",
    "    splitter = fileData['extention'].apply(lambda x: x.split('.'))\n",
    "    try:\n",
    "        fileData['file_name'] = splitter.apply(lambda x: x[0])\n",
    "        fileData['true_extention'] = splitter.apply(lambda x: x[1])\n",
    "#         no true_extention created\n",
    "    except:\n",
    "        pass\n",
    "    return fileData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def handling_leftovers(fileData):\n",
    "    fileData['file_name'].replace(r'$^', np.nan, regex=True, inplace = True)\n",
    "    fileData.fillna(999999, inplace=True)\n",
    "#     print(\"_______________________________\")\n",
    "#     print(fileData['file_name'])\n",
    "    \n",
    "    return fileData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_logger():\n",
    "    create_directory(\"Files2\")\n",
    "    loglevel = logging.INFO            # DEBUG, CRITICAL, WARNING, ERROR\n",
    "    logger = logging.getLogger(\"Application_Logs\")\n",
    "    logger2 = logging.getLogger(\"Application_Logs_Stream\")\n",
    "    if not getattr(logger, 'handler_set', None):\n",
    "        logger.setLevel(logging.INFO)\n",
    "#         Logfile handler\n",
    "        handler = logging.FileHandler('Files2/logs.log')\n",
    "        handler2 = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        logger.addHandler(handler2)\n",
    "        logger.setLevel(loglevel)\n",
    "        logger.handler_set = True\n",
    "#       Stream Handler\n",
    "    if not getattr(logger, 'handler_set', None):\n",
    "        logger2.setLevel(logging.INFO)\n",
    "        handler2 = logging.StreamHandler()\n",
    "        handler2.setFormatter(formatter)\n",
    "        logger2.addHandler(handler2)\n",
    "        logger2.setLevel(loglevel)\n",
    "        logger2.handler_set = True\n",
    "        \n",
    "    return logger\n",
    "\n",
    "\n",
    "def create_directory(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting Cleaning of Data\n",
      "INFO:Application_Logs:Starting Cleaning of Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress : 0%\r",
      "Progress : 1%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning log20030101.csv\n",
      "INFO:Application_Logs:Cleaning log20030101.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress : 3%\r",
      "Progress : 5%\r",
      "Progress : 7%\r",
      "Progress : 10%\r",
      "Progress : 16%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning log20030201.csv\n",
      "INFO:Application_Logs:Cleaning log20030201.csv\n",
      "Cleaning log20030301.csv\n",
      "INFO:Application_Logs:Cleaning log20030301.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress : 22%\r",
      "Progress : 28%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning log20030401.csv\n",
      "INFO:Application_Logs:Cleaning log20030401.csv\n",
      "Cleaning log20030501.csv\n",
      "INFO:Application_Logs:Cleaning log20030501.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress : 34%\r",
      "Progress : 40%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning log20030601.csv\n",
      "INFO:Application_Logs:Cleaning log20030601.csv\n",
      "Cleaning log20030701.csv\n",
      "INFO:Application_Logs:Cleaning log20030701.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress : 46%\r",
      "Progress : 52%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning log20030801.csv\n",
      "INFO:Application_Logs:Cleaning log20030801.csv\n",
      "Cleaning log20030901.csv\n",
      "INFO:Application_Logs:Cleaning log20030901.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress : 58%\r",
      "Progress : 64%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning log20031001.csv\n",
      "INFO:Application_Logs:Cleaning log20031001.csv\n",
      "Cleaning log20031101.csv\n",
      "INFO:Application_Logs:Cleaning log20031101.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress : 70%\r",
      "Progress : 76%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning log20031201.csv\n",
      "INFO:Application_Logs:Cleaning log20031201.csv\n",
      "Cleaning README.txt\n",
      "INFO:Application_Logs:Cleaning README.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress : 82%\n",
      "Data Cleaned and Saved\n",
      "\r",
      "Progress : 100%"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging, sys, time\n",
    "\n",
    "logger = get_logger()\n",
    "logger.info(\"Starting Cleaning of Data\")\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 0)\n",
    "time.sleep(1)\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 1)\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "dir_path = \"Files2\"\n",
    "ls_dir = os.listdir(dir_path)\n",
    "year = 0;\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 3)\n",
    "# Finding Directory or year for which csv are present\n",
    "\n",
    "for file in ls_dir:\n",
    "    regexp = re.compile(r'.txt|.log')\n",
    "#     print(file)\n",
    "    if not(regexp.search(file)):\n",
    "        year = file\n",
    "\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 5)\n",
    "# Setting Directory for the year    \n",
    "if not(year == 0):\n",
    "#     print(year)\n",
    "    dir_path += \"/\" + str(year)\n",
    "else:\n",
    "    print(\"No Files found! Ending Program\")\n",
    "    sys.exit()\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 7)    \n",
    "#Looping over all the csv to load and process the data\n",
    "ls_dir = os.listdir(dir_path)\n",
    "\n",
    "i=1;\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 10)\n",
    "x = 10\n",
    "# print(ls_dir)\n",
    "for file in ls_dir:\n",
    "#     only if file is csv\n",
    "    logger.info(\"Cleaning \" + file)\n",
    "    regexp = re.compile(r'.csv')\n",
    "    if(regexp.search(file)):\n",
    "        filePath = dir_path + \"/\" + file\n",
    "    #   Reading File data with pandas\n",
    "        fileData = pd.read_csv(filePath,header = 0)\n",
    "\n",
    "        \n",
    "#       adding columns for year, month and day of month\n",
    "        fileData = split_date(fileData)\n",
    "#       adding columns for hour, minutes and seconds\n",
    "        fileData = split_time(fileData)\n",
    "#       adding column for true extension\n",
    "        fileData = true_extention(fileData)\n",
    "#       replace empty \"size\" with 0 if code equals 304\n",
    "        fileData = clean_size(fileData) \n",
    "#       removinf code with value 0\n",
    "        fileData = remove_code(fileData)\n",
    "#     replacing all other NaNs with 99999 \n",
    "        fileData = handling_leftovers(fileData)\n",
    "#         print(fileData.shape)\n",
    "#      processed data  \n",
    "        processed_csvs(fileData, filePath,i)\n",
    "        i=i+1;\n",
    "        x+=6\n",
    "        sys.stdout.write(\"\\rProgress : %d%%\" % x)\n",
    "print(\"\\nData Cleaned and Saved\")\n",
    "logger.removeHandler(\"handler\")\n",
    "logging.shutdown()\n",
    "sys.stdout.write(\"\\rProgress : %d%%\" % 100)\n",
    "sys.stdout.flush()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
